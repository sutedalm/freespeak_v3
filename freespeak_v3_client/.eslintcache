[{"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\index.js":"1","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\reportWebVitals.js":"2","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\App.js":"3","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\StartPage.js":"4","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\components\\VideoStream.js":"5","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\components\\PongExecutor.js":"6","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\components\\pong_canvas.js":"7","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\components\\helpPopUp.js":"8"},{"size":517,"mtime":1610795719508,"results":"9","hashOfConfig":"10"},{"size":375,"mtime":1610795719509,"results":"11","hashOfConfig":"10"},{"size":1309,"mtime":1610834337790,"results":"12","hashOfConfig":"10"},{"size":1420,"mtime":1610834351708,"results":"13","hashOfConfig":"10"},{"size":3732,"mtime":1610820262237,"results":"14","hashOfConfig":"10"},{"size":946,"mtime":1610834703188,"results":"15","hashOfConfig":"10"},{"size":12105,"mtime":1610835213577,"results":"16","hashOfConfig":"10"},{"size":1059,"mtime":1610834351709,"results":"17","hashOfConfig":"10"},{"filePath":"18","messages":"19","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"20"},"a9kwxv",{"filePath":"21","messages":"22","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"20"},{"filePath":"23","messages":"24","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"25","messages":"26","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"27","messages":"28","errorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"29","usedDeprecatedRules":"20"},{"filePath":"30","messages":"31","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"32","messages":"33","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"34","messages":"35","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\index.js",[],["36","37"],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\reportWebVitals.js",[],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\App.js",[],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\StartPage.js",["38"],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\components\\VideoStream.js",["39","40","41"],"import \"../../styles/VideoStream.css\";\r\nimport React, { useEffect, useState } from \"react\";\r\n\r\nimport * as faceapi from \"face-api.js\";\r\n\r\nconst VideoStream = ({ width, height, setEmotion}) => {\r\n  // async function test(video, canvas, displaySize) {\r\n  //   const detections = await faceapi\r\n  //       .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())\r\n  //       .withFaceExpressions();\r\n\r\n  //     console.log(detections)\r\n  //     const resizedDetections = faceapi.resizeResults(detections, displaySize);\r\n  //     canvas.getContext(\"2d\").clearRect(0, 0, width, canvas.height);\r\n  //     faceapi.draw.drawDetections(canvas, resizedDetections);\r\n  //     // faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);\r\n  //     faceapi.draw.drawFaceExpressions(canvas, resizedDetections);\r\n\r\n  //     return detections;\r\n  // }\r\n\r\n  function analyze() {\r\n    const video = document.getElementById(\"video\");\r\n    const canvas = document.getElementById(\"canvas\");\r\n    const displaySize = { width: width, height: height };\r\n    faceapi.matchDimensions(canvas, displaySize);\r\n\r\n    setInterval(async () => {\r\n      // const detections = await faceapi\r\n      //   .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())\r\n      //   .withFaceExpressions();\r\n\r\n      const detections = await faceapi\r\n        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())\r\n        .withFaceExpressions();\r\n\r\n      if(detections) {\r\n        setEmotion(detections.expressions);\r\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\r\n        canvas.getContext(\"2d\").clearRect(0, 0, width, canvas.height);\r\n        faceapi.draw.drawDetections(canvas, resizedDetections);\r\n        // faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);\r\n        faceapi.draw.drawFaceExpressions(canvas, resizedDetections);\r\n        }\r\n    }, 100);\r\n    // setInterval(() => test(video, canvas, displaySize), 100);\r\n  }\r\n\r\n  const streamCamVideo = () => {\r\n    const video = document.getElementById(\"video\");\r\n    const canvas = document.getElementById(\"canvas\");\r\n    // input constraints\r\n    var constraints = { audio: true, video: { width: width, height: height } };\r\n    navigator.mediaDevices\r\n      .getUserMedia(constraints)\r\n      .then((mediaStream) => {\r\n        video.srcObject = mediaStream;\r\n        video.onloadedmetadata = function (e) {\r\n          video.play();\r\n        };\r\n      })\r\n      .catch(function (err) {\r\n        console.log(err.name + \": \" + err.message);\r\n      }); // always check for errors at the end.\r\n  };\r\n\r\n  async function loadModels() {\r\n    await Promise.all([\r\n      faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\"),\r\n      faceapi.nets.faceLandmark68TinyNet.loadFromUri(\"/models\"),\r\n      faceapi.nets.faceExpressionNet.loadFromUri(\"/models\"),\r\n    ]);\r\n    // const MODEL_URL = \"/models\";\r\n    // await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\r\n    // await faceapi.nets.faceLandmark68TinyNet.loadFromUri(MODEL_URL);\r\n    // await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);\r\n    console.log(\"loaded models\");\r\n  }\r\n\r\n  useEffect(() => {\r\n    console.log(\"Ich hab geladen\");\r\n    streamCamVideo();\r\n\r\n    // video = document.getElementById(\"video\");\r\n    loadModels().then(analyze());\r\n  }, []);\r\n\r\n  return (\r\n    <div className=\"video-container\" width={width} height={height}>\r\n      <canvas\r\n        className=\"video-canvas\"\r\n        width={width}\r\n        height={height}\r\n        id=\"canvas\"\r\n      ></canvas>\r\n      <video\r\n        className=\"video-output\"\r\n        width={width}\r\n        height={height}\r\n        id=\"video\"\r\n        autoPlay\r\n        muted\r\n      ></video>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default VideoStream;","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\components\\PongExecutor.js",["42"],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\components\\pong_canvas.js",["43"],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\pages\\components\\helpPopUp.js",[],{"ruleId":"44","replacedBy":"45"},{"ruleId":"46","replacedBy":"47"},{"ruleId":"48","severity":1,"message":"49","line":2,"column":10,"nodeType":"50","messageId":"51","endLine":2,"endColumn":18},{"ruleId":"48","severity":1,"message":"52","line":2,"column":28,"nodeType":"50","messageId":"51","endLine":2,"endColumn":36},{"ruleId":"48","severity":1,"message":"53","line":51,"column":11,"nodeType":"50","messageId":"51","endLine":51,"endColumn":17},{"ruleId":"54","severity":1,"message":"55","line":86,"column":6,"nodeType":"56","endLine":86,"endColumn":8,"suggestions":"57"},{"ruleId":"48","severity":1,"message":"52","line":1,"column":28,"nodeType":"50","messageId":"51","endLine":1,"endColumn":36},{"ruleId":"48","severity":1,"message":"58","line":1,"column":8,"nodeType":"50","messageId":"51","endLine":1,"endColumn":20},"no-native-reassign",["59"],"no-negated-in-lhs",["60"],"no-unused-vars","'Redirect' is defined but never used.","Identifier","unusedVar","'useState' is defined but never used.","'canvas' is assigned a value but never used.","react-hooks/exhaustive-deps","React Hook useEffect has missing dependencies: 'analyze' and 'streamCamVideo'. Either include them or remove the dependency array.","ArrayExpression",["61"],"'PongExecutor' is defined but never used.","no-global-assign","no-unsafe-negation",{"desc":"62","fix":"63"},"Update the dependencies array to be: [analyze, streamCamVideo]",{"range":"64","text":"65"},[3290,3292],"[analyze, streamCamVideo]"]