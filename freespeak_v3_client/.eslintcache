[{"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\index.js":"1","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\App.js":"2","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\reportWebVitals.js":"3","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\components\\VideoStream.js":"4","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\components\\PongExecutor.js":"5","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\components\\pong_canvas.js":"6"},{"size":517,"mtime":1610795719508,"results":"7","hashOfConfig":"8"},{"size":236,"mtime":1610802618750,"results":"9","hashOfConfig":"8"},{"size":375,"mtime":1610795719509,"results":"10","hashOfConfig":"8"},{"size":2223,"mtime":1610799366235,"results":"11","hashOfConfig":"8"},{"size":287,"mtime":1610802817431,"results":"12","hashOfConfig":"8"},{"size":11646,"mtime":1610810420776,"results":"13","hashOfConfig":"8"},{"filePath":"14","messages":"15","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"16"},"a9kwxv",{"filePath":"17","messages":"18","errorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"19","messages":"20","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"16"},{"filePath":"21","messages":"22","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"23","usedDeprecatedRules":"16"},{"filePath":"24","messages":"25","errorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"26","messages":"27","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\index.js",[],["28","29"],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\App.js",["30","31"],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\reportWebVitals.js",[],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\components\\VideoStream.js",["32"],"import React, { useEffect, useState } from \"react\";\r\n\r\nimport * as faceapi from \"face-api.js\";\r\n\r\nfunction analyze(video) {\r\n  const canvas = faceapi.createCanvasFromMedia(video);\r\n  document.body.append(canvas);\r\n  const displaySize = { width: video.width, height: video.height };\r\n  faceapi.matchDimensions(canvas, displaySize);\r\n  setInterval(async () => {\r\n    const detections = await faceapi\r\n      .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())\r\n      .withFaceLandmarks()\r\n      .withFaceExpressions();\r\n    const resizedDetections = faceapi.resizeResults(detections, displaySize);\r\n    canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\r\n    faceapi.draw.drawDetections(canvas, resizedDetections);\r\n    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);\r\n    faceapi.draw.drawFaceExpressions(canvas, resizedDetections);\r\n  }, 100);\r\n}\r\nconst streamCamVideo = () => {\r\n  // input constraints\r\n  var constraints = { audio: true, video: { width: 1280, height: 720 } };\r\n  navigator.mediaDevices\r\n    .getUserMedia(constraints)\r\n    .then((mediaStream) => {\r\n      var video = document.getElementById(\"video\");\r\n\r\n      video.srcObject = mediaStream;\r\n      video.onloadedmetadata = function (e) {\r\n        video.play();\r\n      };\r\n      video.addEventListener(\"play\", analyze(video));\r\n      return video;\r\n    })\r\n    .catch(function (err) {\r\n      console.log(err.name + \": \" + err.message);\r\n    }); // always check for errors at the end.\r\n};\r\n\r\nasync function loadModels() {\r\n  await Promise.all([\r\n    faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\"),\r\n    faceapi.nets.faceLandmark68Net.loadFromUri(\"/models\"),\r\n    faceapi.nets.faceRecognitionNet.loadFromUri(\"/models\"),\r\n    faceapi.nets.faceExpressionNet.loadFromUri(\"/models\"),\r\n  ]);\r\n}\r\n\r\nconst VideoStream = () => {\r\n  let video;\r\n\r\n  useEffect(() => {\r\n    console.log(\"Ich hab geladen\");\r\n\r\n    // video = document.getElementById(\"video\");\r\n    loadModels().then(() => {\r\n      const video = streamCamVideo();\r\n      analyze(video);\r\n    });\r\n  }, []);\r\n\r\n  return (\r\n    <div>\r\n      <video id=\"video\" width=\"720\" height=\"560\" autoPlay muted></video>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default VideoStream;\r\n","C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\components\\PongExecutor.js",["33","34"],"C:\\Users\\Masha\\Documents\\programming\\freespeak_v3\\freespeak_v3_client\\src\\components\\pong_canvas.js",["35"],{"ruleId":"36","replacedBy":"37"},{"ruleId":"38","replacedBy":"39"},{"ruleId":"40","severity":1,"message":"41","line":1,"column":8,"nodeType":"42","messageId":"43","endLine":1,"endColumn":12},{"ruleId":"40","severity":1,"message":"44","line":3,"column":8,"nodeType":"42","messageId":"43","endLine":3,"endColumn":19},{"ruleId":"40","severity":1,"message":"45","line":1,"column":28,"nodeType":"42","messageId":"43","endLine":1,"endColumn":36},{"ruleId":"40","severity":1,"message":"45","line":1,"column":28,"nodeType":"42","messageId":"43","endLine":1,"endColumn":36},{"ruleId":"40","severity":1,"message":"46","line":2,"column":16,"nodeType":"42","messageId":"43","endLine":2,"endColumn":25},{"ruleId":"40","severity":1,"message":"47","line":1,"column":8,"nodeType":"42","messageId":"43","endLine":1,"endColumn":20},"no-native-reassign",["48"],"no-negated-in-lhs",["49"],"no-unused-vars","'logo' is defined but never used.","Identifier","unusedVar","'VideoStream' is defined but never used.","'useState' is defined but never used.","'DIRECTION' is defined but never used.","'PongExecutor' is defined but never used.","no-global-assign","no-unsafe-negation"]